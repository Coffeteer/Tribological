Environment = as.factor(Environment),
Food  = as.factor(Food))
friedman.test(Appear ~ Environment | Subject, data = df)
glimpse(df)
# Perform the Friedman test
friedman_test_result <- df %>%
select(Subject, Environment, Food, Appear, Smell, Mouthfeel, Flavor, Prodacc) %>%
pivot_longer(cols = c(Appear, Smell, Mouthfeel, Flavor, Prodacc), names_to = "Variable", values_to = "Value") %>%
group_by(Variable) %>%
friedman.test(Value ~ Environment:Food | Subject, data = .)
# Perform the Friedman test
friedman_df <- df %>%
select(Subject, Environment, Food, Appear, Smell, Mouthfeel, Flavor, Prodacc) %>%
pivot_longer(cols = c(Appear, Smell, Mouthfeel, Flavor, Prodacc), names_to = "Variable", values_to = "Value") %>%
group_by(Variable)
friedman.test(Value ~ Environment:Food | Subject, data = friedman_df)
View(friedman_df)
friedman_test_results <- df %>%
select(Subject, Environment, Food, Appear, Smell, Mouthfeel, Flavor, Prodacc) %>%
pivot_longer(cols = c(Appear, Smell, Mouthfeel, Flavor, Prodacc), names_to = "Variable", values_to = "Value") %>%
group_by(Variable) %>%
summarise(result = list(friedman.test(Value ~ Environment | Subject, data = cur_data())))
df <- read_xlsx(path = "ar_taste_data.xlsx",range = "A24:H474") %>% fill(Subject)
subj_long <- read_xlsx(path = "ar_taste_data.xlsx",range = "A9:CO20")
subj_long <- read_xlsx(path = "ar_taste_data.xlsx",range = "A9:CO20")
subj <- read_xlsx(path = "ar_taste_data.xlsx",range = "J27:L38")
subj <- read_xlsx(path = "ar_taste_data.xlsx",range = "J27:L38")
# Create DF for holding extracted subject ID's and Start Times
Subject_df<- data.frame("Subject" = NA, "Start_time" = NA)
Subject_df$Start_time <- as.POSIXct(Subject_df$Start_time)
# Get time of  subject start
Subject_df$Start_time[1] <- as.POSIXct((as.numeric(names(subj)[2])-1.625) * 86400, origin = "1900-01-01")
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138.0`[3]
# Reset Column Names
names(subj) <- subj[5,]
subj$`45138.0`[3]
subj <- read_xlsx(path = "ar_taste_data.xlsx",range = "J27:L38")
View(subj)
# Create DF for holding extracted subject ID's and Start Times
Subject_df<- data.frame("Subject" = NA, "Start_time" = NA)
Subject_df$Start_time <- as.POSIXct(Subject_df$Start_time)
# Get time of  subject start
Subject_df$Start_time[1] <- as.POSIXct((as.numeric(names(subj)[2])-1.625) * 86400, origin = "1900-01-01")
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138.0`[3]
subj$`45138.0`[3]
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138`[3]
# Create DF for holding extracted subject ID's and Start Times
Subject_df<- data.frame("Subject" = NA, "Start_time" = NA)
Subject_df$Start_time <- as.POSIXct(Subject_df$Start_time)
# Get time of  subject start
Subject_df$Start_time[1] <- as.POSIXct((as.numeric(names(subj)[2])-1.625) * 86400, origin = "1900-01-01")
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138`[3]
# Reset Column Names
names(subj) <- subj[5,]
# Subset to only data
subj <- subj[7:11,]
# Apply the substr function to extract the last character of each string
subj <- apply(subj, c(1, 2), function(x) substr(x, nchar(x), nchar(x)))
# Convert the result to a dataframe
subj <- as.data.frame(subj)
subj <- subj %>%
pivot_longer(everything(), names_to = "Environment", values_to = "Food", cols_vary = "slowest") %>%
mutate(Environment = case_when(
Environment == "Blue - Lake" ~ 2,
Environment == "Yellow - Control" ~ 1,
Environment == "Red - Hospital" ~ 3
))
df <- read_xlsx(path = "ar_taste_data.xlsx",range = "A24:H474") %>% fill(Subject)
subj_long <- read_xlsx(path = "ar_taste_data.xlsx",range = "A9:CO20")
subj <- read_xlsx(path = "ar_taste_data.xlsx",range = "J27:L38")
# Create DF for holding extracted subject ID's and Start Times
Subject_df<- data.frame("Subject" = NA, "Start_time" = NA)
Subject_df$Start_time <- as.POSIXct(Subject_df$Start_time)
# Get time of  subject start
Subject_df$Start_time[1] <- as.POSIXct((as.numeric(names(subj)[2])-1.625) * 86400, origin = "1900-01-01")
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138`[3]
# Reset Column Names
names(subj) <- subj[5,]
# Subset to only data
subj <- subj[7:11,]
# Apply the substr function to extract the last character of each string
subj <- apply(subj, c(1, 2), function(x) substr(x, nchar(x), nchar(x)))
# Convert the result to a dataframe
subj <- as.data.frame(subj)
subj <- subj %>%
pivot_longer(everything(), names_to = "Environment", values_to = "Food", cols_vary = "slowest") %>%
mutate(Environment = case_when(
Environment == "Blue - Lake" ~ 2,
Environment == "Yellow - Control" ~ 1,
Environment == "Red - Hospital" ~ 3
))
subj <- subj %>%
pivot_longer(everything(), names_to = "Environment", values_to = "Food", cols_vary = "slowest") %>%
mutate(Environment = case_when(
Environment == "Blue - Lake" ~ 2,
Environment == "Yellow - Control" ~ 1,
Environment == "Red - Hospital" ~ 3
))
# Convert the result to a dataframe
subj <- as.data.frame(subj)
df <- read_xlsx(path = "ar_taste_data.xlsx",range = "A24:H474") %>% fill(Subject)
subj_long <- read_xlsx(path = "ar_taste_data.xlsx",range = "A9:CO20")
subj <- read_xlsx(path = "ar_taste_data.xlsx",range = "J27:L38")
# Create DF for holding extracted subject ID's and Start Times
Subject_df<- data.frame("Subject" = NA, "Start_time" = NA)
Subject_df$Start_time <- as.POSIXct(Subject_df$Start_time)
# Get time of  subject start
Subject_df$Start_time[1] <- as.POSIXct((as.numeric(names(subj)[2])-1.625) * 86400, origin = "1900-01-01")
# Extract Subject ID
Subject_df$Subject[1] <- subj$`45138`[3]
# Reset Column Names
names(subj) <- subj[5,]
# Subset to only data
subj <- subj[7:11,]
# Apply the substr function to extract the last character of each string
subj <- apply(subj, c(1, 2), function(x) substr(x, nchar(x), nchar(x)))
# Convert the result to a dataframe
subj <- as.data.frame(subj)
subj <- subj %>%
pivot_longer(everything(), names_to = "Environment", values_to = "Food", cols_vary = "slowest") %>%
mutate(Environment = case_when(
Environment == "Blue - Lake" ~ 2,
Environment == "Yellow - Control" ~ 1,
Environment == "Red - Hospital" ~ 3
))
?ndiffs
knitr::opts_chunk$set(echo = TRUE)
# turn on the tidyverse package
library(tidyverse)
# Read-in data
uwec <- read.csv("uwec.csv", header=TRUE)
# Data preparation
uwec %>%
select(sex, gpa)
# Data preparation
uwec %>%
select(sex, gpa) %>%
hist()
# Data preparation
uwec %>%
select(sex, gpa) %>%
hist(gpa)
# Data preparation
uwec %>%
select(sex, gpa) %>%
# Code to run the test
hist(uwec$gpa)
# Code to run the test
hist(uwec$gpa)
# Data preparation
uwec %>%
select(sex, gpa)  %>%
mutate(high_gpa = case_when(
gpa > 3 ~ 1,
gpa <= 3 ~ 0
))
# Data preparation
uwec_1 <- uwec %>%
select(sex, gpa)  %>%
mutate(high_gpa = case_when(
gpa > 3 ~ 1,
gpa <= 3 ~ 0
))
table(uwec_1)
# Data preparation
uwec_1 <- uwec %>%
mutate(high_gpa = case_when(
gpa > 3 ~ 1,
gpa <= 3 ~ 0
)) %>%
select(sex, high_gpa)
table(uwec_1)
my_table <- table(uwec_1)
fisher.test(mytable)
fisher.test(my_table)
unique(uwec$college)
# Data preparation
uwec_1 <- uwec %>%
filter(college == "A&S")
# Data preparation
uwec_1 <- uwec %>%
filter(college == "A&S") %>%
mutate(high_gpa = case_when(
gpa > 3 ~ 1,
gpa <= 3 ~ 0
)) %>%
select(sex, high_gpa)
my_table <- table(uwec_1)
fisher.test(my_table)
my_table
fisher.test(my_table)
# Code to run the test
prop.table(my_table, 1)
fisher.test(my_table)
hist(uwec$comp)
# Data preparation
uwec$residency
# Data preparation
uwec$residency == "Resident"
# Data preparation
uwec[uwec$residency == "Resident"]
# Data preparation
uwec$residency[uwec$residency == "Resident"]
# Data preparation
uwec[uwec$residency == "Resident"]
# Data preparation
uwec$comp[uwec$residency == "Resident"]
# Data preparation
median(uwec$comp[uwec$residency == "Resident"])
median(uwec$comp[uwec$residency == "NonResident"])
median(uwec$comp[uwec$residency == "Nonresident"])
# Data preparation
median(uwec$comp[uwec$residency == "Resident"])
median(uwec$comp[uwec$residency == "Nonresident"])
library(exactRankTests)
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
library(exactRankTests)
# Set a seed value for reproducible results
set.seed(8224166)
# Data preparation
median(uwec$comp[uwec$residency == "Resident"])
median(uwec$comp[uwec$residency == "Nonresident"])
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
library(exactRankTests)
# Set a seed value for reproducible results
set.seed(8224166)
# Data preparation
dev.res <-median(uwec$comp[uwec$residency == "Resident"])
dev.non <- median(uwec$comp[uwec$residency == "Nonresident"])
R <- 9999
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
all <- c(dev.res,dev.non)
k <- 1:length(all)
reps <- numeric(R)
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
RMD <- (sum(abs(dev.res))/length(dev.res))/(sum(abs(dev.non))/length(dev.non))
RMD
for (i in 1:R) {
m <- sample(k, size=length(dev.res), replace=FALSE)
p.res <- all[m]
p.non <- all[-m]
reps[i] <- (sum(abs(p.res))/length(p.res))/(sum(abs(p.non))/length(p.non))
}
# calculate two-tailed p-value
if (RMD > 1) pvalue <- mean(c(RMD , reps) >= RMD) + mean(c(RMD , reps) <= 1/RMD)
if (RMD < 1) pvalue <- mean(c(RMD , reps) <= RMD) + mean(c(RMD , reps) >= 1/RMD)
if (RMD == 1) pvalue <- 1
pvalue
hist(reps, main="Null distribution of RMD")
abline(v=RMD, lty=2 ,col="red")
pvalue
# Data preparation
dev.res <-median(uwec$comp[uwec$residency == "Resident"])
dev.non <- median(uwec$comp[uwec$residency == "Nonresident"])
library(exactRankTests)
# Set a seed value for reproducible results
set.seed(8224166)
# Data preparation
dev.res <-median(uwec$comp[uwec$residency == "Resident"])
dev.non <- median(uwec$comp[uwec$residency == "Nonresident"])
R <- 9999
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
all <- c(dev.res,dev.non)
k <- 1:length(all)
reps <- numeric(R)
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
RMD <- (sum(abs(dev.res))/length(dev.res))/(sum(abs(dev.non))/length(dev.non))
RMD
for (i in 1:R) {
m <- sample(k, size=length(dev.res), replace=FALSE)
p.res <- all[m]
p.non <- all[-m]
reps[i] <- (sum(abs(p.res))/length(p.res))/(sum(abs(p.non))/length(p.non))
}
# calculate two-tailed p-value
if (RMD > 1) pvalue <- mean(c(RMD , reps) >= RMD) + mean(c(RMD , reps) <= 1/RMD)
if (RMD < 1) pvalue <- mean(c(RMD , reps) <= RMD) + mean(c(RMD , reps) >= 1/RMD)
if (RMD == 1) pvalue <- 1
pvalue
hist(reps, main="Null distribution of RMD")
abline(v=RMD, lty=2 ,col="red")
library(exactRankTests)
# Set a seed value for reproducible results
set.seed(8224166)
# Data preparation
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
dev.res <-resident - median(uwec$comp[uwec$residency == "Resident"])
dev.non <- nonres - median(uwec$comp[uwec$residency == "Nonresident"])
R <- 9999
all <- c(dev.res,dev.non)
k <- 1:length(all)
reps <- numeric(R)
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
RMD <- (sum(abs(dev.res))/length(dev.res))/(sum(abs(dev.non))/length(dev.non))
RMD
for (i in 1:R) {
m <- sample(k, size=length(dev.res), replace=FALSE)
p.res <- all[m]
p.non <- all[-m]
reps[i] <- (sum(abs(p.res))/length(p.res))/(sum(abs(p.non))/length(p.non))
}
# calculate two-tailed p-value
if (RMD > 1) pvalue <- mean(c(RMD , reps) >= RMD) + mean(c(RMD , reps) <= 1/RMD)
if (RMD < 1) pvalue <- mean(c(RMD , reps) <= RMD) + mean(c(RMD , reps) >= 1/RMD)
if (RMD == 1) pvalue <- 1
pvalue
hist(reps, main="Null distribution of RMD")
abline(v=RMD, lty=2 ,col="red")
pvalue
library(exactRankTests)
# Set a seed value for reproducible results
set.seed(8224166)
# Data preparation
resident <- uwec$comp[uwec$residency == "Resident"]
nonres <- uwec$comp[uwec$residency == "Nonresident"]
dev.res <-resident - median(uwec$comp[uwec$residency == "Resident"])
dev.non <- nonres - median(uwec$comp[uwec$residency == "Nonresident"])
R <- 9999
all <- c(dev.res,dev.non)
k <- 1:length(all)
reps <- numeric(R)
# Code to run the test
ansari.exact(resident, nonres, alternative = "two.sided")
RMD <- (sum(abs(dev.res))/length(dev.res))/(sum(abs(dev.non))/length(dev.non))
RMD
for (i in 1:R) {
m <- sample(k, size=length(dev.res), replace=FALSE)
p.res <- all[m]
p.non <- all[-m]
reps[i] <- (sum(abs(p.res))/length(p.res))/(sum(abs(p.non))/length(p.non))
}
# calculate two-tailed p-value
if (RMD > 1) pvalue <- mean(c(RMD , reps) >= RMD) + mean(c(RMD , reps) <= 1/RMD)
if (RMD < 1) pvalue <- mean(c(RMD , reps) <= RMD) + mean(c(RMD , reps) >= 1/RMD)
if (RMD == 1) pvalue <- 1
pvalue
hist(reps, main="Null distribution of RMD")
abline(v=RMD, lty=2 ,col="red")
RMD
pvalue
?calculate
# Set a seed value for reproducible results
set.seed(888813)
# Perform bootstrapping
d_hat <- uwec %>%
specify(comp ~ residency) %>%
calculate(stat = "diff in medians", order = c("Resident", "Nonresident"))
library(infer)
# Perform bootstrapping
d_hat <- uwec %>%
specify(comp ~ residency) %>%
calculate(stat = "diff in medians", order = c("Resident", "Nonresident"))
boot_dist <- uwec %>%
specify(comp ~ residency) %>%
generate(reps = 10000, type = "bootstrap") %>%
calculate(stat = "diff in medians", order = c("Resident", "Nonresident"))
percentile_ci <- get_ci(boot_dist)
visualize(boot_dist) +
shade_confidence_interval(endpoints = percentile_ci)
percentile_ci
length(resident)
length(nonres)
library(infer)
# Set a seed value for reproducible results
set.seed(888813)
# Perform bootstrapping
d_hat <- uwec %>%
specify(comp ~ residency) %>%
calculate(stat = "diff in medians", order = c("Resident", "Nonresident"))
boot_dist <- uwec %>%
specify(comp ~ residency) %>%
generate(reps = 10000, type = "bootstrap") %>%
calculate(stat = "diff in medians", order = c("Resident", "Nonresident"))
percentile_ci <- get_ci(boot_dist)
percentile_ci
visualize(boot_dist) +
shade_confidence_interval(endpoints = percentile_ci)
dev.res
for (i in 1:10000) {
boot_sample1 <- sample(resident, size = 150, replace = TRUE)
boot_sample2 <- sample(nonres, size = 150, replace = TRUE)
bootstats[i] <- (sum(abs(boot_sample1))/length(boot_sample1))/(sum(abs(boot_sample2))/length(boot_sample2))
}
bootstats<- c()
for (i in 1:10000) {
boot_sample1 <- sample(resident, size = 150, replace = TRUE)
boot_sample2 <- sample(nonres, size = 150, replace = TRUE)
bootstats[i] <- (sum(abs(boot_sample1))/length(boot_sample1))/(sum(abs(boot_sample2))/length(boot_sample2))
}
hist(bootstats)
mean(bootstats)
sd(bootstats)
dev.res <-resident - median(uwec$comp[uwec$residency == "Resident"])
dev.non <- nonres - median(uwec$comp[uwec$residency == "Nonresident"])
RMD.obs <- mean(abs(dev.res))/mean(abs(dev.non))
RMD.obs
RMD.boots <- numeric(2000)
dev.res <-resident - median(uwec$comp[uwec$residency == "Resident"])
dev.non <- nonres - median(uwec$comp[uwec$residency == "Nonresident"])
RMD.obs <- mean(abs(dev.res))/mean(abs(dev.non))
RMD.obs
# Set a seed value for reproducible results
set.seed(888813)
# Perform bootstrapping
RMD.boots <- numeric(2000)
for (i in 1:2000) {
boot_sample1 <- sample(resident, size = length(resident), replace = TRUE)
dev.bootsample1 <- boot_sample1 - median(boot_sample1)
boot_sample2 <- sample(noneres, size = length(nonres), replace = TRUE)
dev.bootsample2 <- boot_sample2 - median(boot_sample2)
RMD.boots[i] <- (sum(abs(dev.bootsample1))/length(dev.bootsample1))/(sum(abs(dev.bootsample2))/length(dev.bootsample2))
}
dev.res <-resident - median(uwec$comp[uwec$residency == "Resident"])
dev.non <- nonres - median(uwec$comp[uwec$residency == "Nonresident"])
RMD.obs <- mean(abs(dev.res))/mean(abs(dev.non))
RMD.obs
# Set a seed value for reproducible results
set.seed(888813)
# Perform bootstrapping
RMD.boots <- numeric(2000)
for (i in 1:2000) {
boot_sample1 <- sample(resident, size = length(resident), replace = TRUE)
dev.bootsample1 <- boot_sample1 - median(boot_sample1)
boot_sample2 <- sample(nonres, size = length(nonres), replace = TRUE)
dev.bootsample2 <- boot_sample2 - median(boot_sample2)
RMD.boots[i] <- (sum(abs(dev.bootsample1))/length(dev.bootsample1))/(sum(abs(dev.bootsample2))/length(dev.bootsample2))
}
hist(bootstats)
mean(bootstats)
sd(bootstats)
quantile(RMD.boots)
quantile(RMD.boots, c(0.025, 0.975))
knitr::opts_chunk$set(echo = TRUE, fig.width = 4,fig.height = 4)
y = c(18.3, 19.4, 19.7, 23.4, 30.9, 21.7, 21.7, 21.4, 26.3, 25.3)
library(rstan)
y = c(18.3, 19.4, 19.7, 23.4, 30.9, 21.7, 21.7, 21.4, 26.3, 25.3)
datlist = list(y = y, n = length(y))
stanfit = sampling(normal_model,data = datlist, seed=1, chains=2,
warmup=5000,iter=15000)
print(stanfit)
## posterior mean for two parameters.
# Extract posterior samples from RStan output
samples = rstan::extract(stanfit)
# posterior means
mupost = mean(samples$mu)
sig2post = mean(samples$sigma2)
# Deviance evaluated with the posterior mean of the parameters
Dbayes = -2*sum(dnorm(y, mean = mupost, sd = sqrt(sig2post), log = TRUE))
# Posterior mean of Deviance
loglik.post=samples$log_lik
Dev.post=-2*apply(loglik.post,1,sum)
Dbar=mean(Dev.post)
### Effective number of parameters
pd1=Dbar-Dbayes
pd1
### You could also make use the "rowSums()"
#pd1 = -2*mean(rowSums(samples$log_lik)) - Dbayes
# DIC value
DIC1 = Dbayes + pd1
DIC1
# If you wish to use the alternative definition of effective sample sizes, you could use
loglik.all.post=apply(loglik.post,1,sum)
pd2=2*var(loglik.all.post)
pd2
# DIC value
DIC2 = Dbayes + pd2
DIC2
### WAIC ###
library(loo)
waic(samples$log_lik)
shiny::runApp('Tribological_Visuals')
runApp('Sample_App')
runApp('Sample_App')
experiment_data <- readRDS("../RDS_files/experiment_summaries.rds")
experiment_data <- readRDS("..//RDS_files//experiment_summaries.rds")
getwd()
experiment_data <- readRDS(".//RDS_files//experiment_summaries.rds")
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
runApp('Tribological_Visuals')
?consump
?diffs
?diff
